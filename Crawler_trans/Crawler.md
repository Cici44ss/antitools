# web 异步协同爬虫
原文[地址](http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html)
作者:
- A. Jesse Jiryu Davis(美国MongoDB 工程师，MongoDB 的py驱动的作者，主导mongoDB的c驱动)
- Guido van Rossum (不说了)

## 介绍
经典计算机理论强调高效率的算法，尽可能快速的完成计算。但是大多数的网络相关时间瓶颈并没有在计算上，打开较慢的连接，或者不频繁的事件。此项目目标：提高网络爬虫效率，当前处理方法是使用异步 i/o 或者 “异步”。

此章节建立一个简单的web 爬虫，爬虫的原型为异步应用因为要等待诸多相应，仅仅做少量计算。一次获取的页面越多，计算完成的就越快。如果每个请求都分配一个线程，则随着并发请求的增加，它将耗尽内存或者其他线程的资源，直到耗尽 sockets，通过使用异步i/o避免了线程的开销。

我们迭代了三次完成这个项目

- 第一次，做一个异步事件轮询，并写一个带有回调事件循环的爬虫，这样做的效率很高，但带来的是扩展性和复杂度将会导致无法扩展和维护的代码。
- 第二次，使用python的协程，可以同时达到效率和扩展性，我们实现了简单的协程在python中使用生成器方法。
- 第三次，我们使用标准库的异步和协程的全部特性，当然需要异步队列来实现调度。


